<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CloudLSVA Document - Pages 11 and 12</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
        }
        h1, h2, h3 {
            color: #333;
        }
        h1 {
            font-size: 1.8em;
        }
        h2 {
            font-size: 1.5em;
        }
        h3 {
            font-size: 1.2em;
        }
        p {
            margin: 10px 0;
        }
        .figure {
            font-style: italic;
            color: #555;
            margin: 10px 0;
            text-align: center;
        }
        .figure img {
            max-width: 100%;
            height: auto;
            margin-top: 5px;
            border: 1px solid #ddd;
            margin: 5px;
        }
        .subfigure {
            display: inline-block;
            margin: 5px;
            vertical-align: top;
        }
        .subfigure-label {
            font-size: 0.9em;
            margin-top: 5px;
        }
    </style>
</head>
<body>
    <h1>CloudLSVA</h1>
    <h2>D1.1</h2>
    <h2>F</h2>

    <h3>2.1.1 Phase 1: On Sidewalk / City Inter-urban</h3>
    <p>In Phase I, the proposed use cases are borrowed from AEB NCAP car-to-pedestrian scenario, where the pedestrian is assumed to initiate road crossing from the sidewalk (near side) irrespective of occlusion state. In both situations, it is assumed that the driver of the vehicle is braking to avoid collision.</p>
    <div class="figure">
        <div class="subfigure">
            <img src="images/figure1a.png" alt="Figure 1a: Pedestrian on sidewalk">
            <div class="subfigure-label">Figure 1a</div>
        </div>
        <div class="subfigure">
            <img src="images/figure1b.png" alt="Figure 1b: Pedestrian on sidewalk">
            <div class="subfigure-label">Figure 1b</div>
        </div>
        <div>Figure 1: Pedestrian on sidewalk.</div>
    </div>
    <p>The proposed use-cases focus primarily around braking situations where the target vehicle may be stopped, slow moving or braking (similarly to NCAP car-to-car-rear scenarios). No assumption is made about the location of the vehicles (Urban, inter-urban, etc.).</p>
    <div class="figure">
        <div class="subfigure">
            <img src="images/figure2a.png" alt="Figure 2a: Stopped-Slow-Braking">
            <div class="subfigure-label">Figure 2a</div>
        </div>
        <div class="subfigure">
            <img src="images/figure2b.png" alt="Figure 2b: Stopped-Slow-Braking">
            <div class="subfigure-label">Figure 2b</div>
        </div>
        <div class="subfigure">
            <img src="images/figure2c.png" alt="Figure 2c: Stopped-Slow-Braking">
            <div class="subfigure-label">Figure 2c</div>
        </div>
        <div>Figure 2: Stopped-Slow-Braking.</div>
    </div>

    <h3>2.1.2 Phase 2: On Roadway / City Inter-urban</h3>
    <p>In Phase II, pedestrians/cyclists are assumed to be on the roadway: either walking along the road in the direction of travel or crossing from the far side. For the first case, collision avoidance can either be done by steering or by braking; both maneuvers are also possible.</p>
    <div class="figure">
        <div class="subfigure">
            <img src="images/figure3a.png" alt="Figure 3a: Pedestrian on Roadway">
            <div class="subfigure-label">Figure 3a</div>
        </div>
        <div class="subfigure">
            <img src="images/figure3b.png" alt="Figure 3b: Pedestrian on Roadway">
            <div class="subfigure-label">Figure 3b</div>
        </div>
        <div>Figure 3: Pedestrian on Roadway.</div>
    </div>
    <p>The focus moves towards obstacle avoidance in terms of full or partial lane change. In the first case, situations, where the subject vehicle needs to carry an overtaking manoeuvre are considered. In the latter case, the subject may need to detect free space to avoid, for instance, construction work.</p>
    <div class="figure">
        <div class="subfigure">
            <img src="images/figure4a.png" alt="Figure 4a: Overtaking & Narrow passage-detection free space">
            <div class="subfigure-label">Figure 4a</div>
        </div>
        <div class="subfigure">
            <img src="images/figure4b.png" alt="Figure 4b: Overtaking & Narrow passage-detection free space">
            <div class="subfigure-label">Figure 4b</div>
        </div>
        <div>Figure 4: Overtaking & Narrow passage-detection free space.</div>
    </div>

    <h3>2.1.3 Phase 3: Realistic Combinations City / Highway</h3>
    <p>In Phase III, the above mentioned use cases can be merged into a single use-case. The objective here is to ensure that it is possible to annotate a complex situation.</p>
    <div class="figure">
        <div class="subfigure">
            <img src="images/figure5.png" alt="Figure 5: Realistic combinations - Pedestrian to car">
            <div class="subfigure-label">Figure 5</div>
        </div>
        <div>Figure 5: Realistic combinations - Pedestrian to car.</div>
    </div>
    <p>As shown in Figure 6, complex multi-lane scenarios should be considered.</p>
    <div class="figure">
        <div class="subfigure">
            <img src="images/figure6.png" alt="Figure 6: Realistic combinations - Car to car">
            <div class="subfigure-label">Figure 6</div>
        </div>
        <div>Figure 6: Realistic combinations - Car to car.</div>
    </div>

    <h3>2.2 Annotation for Cartography generation</h3>
    <p>For Tom Tom, "Lane-level" navigation is an incremental step from road-navigation technology for infotainment systems towards cooperative-navigation technology for highly automated driving (HAD).</p>
    <p>It is essential to keep the map in sync with reality for lane-level navigation and even more for automated driving. Conventional map making techniques no longer meet the right level of freshness. Crowd sourcing technologies are explored as a new way of map making. These implement a near real-time loop of updating the on-board map on the basis of deviations of this map with real-time information of ca's exo-sensors (i.e. camera, radar, LIDAR). The changes are committed to the back office to improve the next map.</p>
    <p>The process to produce map updates is automated with map-object classifiers that can run in the cloud environment for map production and can run in the vehicle system for lane positioning.</p>
    <p>Highly accurate annotation of pictures or videos is key to train the map object classifiers and achieve the goal of an ever improving map.</p>
</body>
</html>